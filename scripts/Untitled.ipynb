{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob,random\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import shlex\n",
    "import gc\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble, metrics \n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import (RandomOverSampler, SMOTE, ADASYN)\n",
    "from collections import Counter\n",
    "import sys, traceback\n",
    "import threading\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_model_name = \"ST4000DM000\"\n",
    "#disk_model_name = \"ST8000DM002\"\n",
    "#disk_model_name = \"ST8000NM0055\"\n",
    "#disk_model_name = \"ST12000NM0007\"\n",
    "#disk_model_name = \"ST6000DX000\" //error\n",
    "#disk_model_name = \"ST10000NM0086\" //error\n",
    "\n",
    "number_of_days = 1\n",
    "\n",
    "map_list = []\n",
    "index_map ={}\n",
    "date_dict={}\n",
    "now = time.time()\n",
    "count=-1\n",
    "file_name=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89061\n"
     ]
    }
   ],
   "source": [
    "with open(\"../map_2019.txt\",\"r\")as in_file:\n",
    "    for line in in_file:\n",
    "        if(len(line.strip())>0):\n",
    "            if\".csv\" in line:\n",
    "                if(count!=-1):\n",
    "                    map_list.append(date_dict)\n",
    "                    index_map[file_name]=count\n",
    "                \n",
    "                date_dict.clear()\n",
    "                count+=1\n",
    "                file_name=line.strip()\n",
    "            else:\n",
    "                parts = line.strip().split(\" \")\n",
    "                date_dict[parts[0]] = int(float(parts[1]))\n",
    "                    \n",
    "#                print(line)\n",
    "                \n",
    "                \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lable(serial_number_list,date,year,month,day):\n",
    "    global parent_folder_name\n",
    "    next_day_label =[]\n",
    "    \n",
    "    now = datetime.datetime(year,month,day)\n",
    "    next_day = (now + datetime.timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    for x in serial_number_list:\n",
    "        index = index_map[x+\".csv\"]\n",
    "        current_value = map_list[index][date]\n",
    "        \n",
    "        next_day_value = map_list[index][next_day]\n",
    "        \n",
    "        if(current_value==next_day_value):\n",
    "            next_day_label.append(0)\n",
    "        else:\n",
    "            next_day_label.append(1)\n",
    "        \n",
    "    return next_day_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error_prob(prob_list):\n",
    "    final_prob =0\n",
    "    for x in range(len(prob_list)):\n",
    "        i = prob_list[x]\n",
    "        for y in range(len(prob_list)):\n",
    "            if x!=y:\n",
    "                i=i*(1-prob_list[y])\n",
    "        final_prob+=i\n",
    "#    print(final_prob)\n",
    "    return final_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_disk(prob_list, n, threshold):\n",
    "    alpha = .9\n",
    "    min_cost = 999999\n",
    "    from itertools import combinations, chain\n",
    "#    n = len(serial_number_list)\n",
    "    allsubsets = lambda n: list(chain(*[combinations(range(n), ni) for ni in range(n+1)]))\n",
    "    selected_subset=[]\n",
    "    all_list=[i for i in range(n)]\n",
    "    for x in allsubsets(n):\n",
    "        temp_list=[]\n",
    "        for y in x:\n",
    "            temp_list.append(y)\n",
    "        \n",
    "        \n",
    "        un_selected_list=(list(set(all_list) - set(temp_list)))\n",
    "        slected_prob_list = []\n",
    "        for i in un_selected_list:\n",
    "            slected_prob_list.append(prob_list[:,1][i])\n",
    "        \n",
    "        prob = calculate_error_prob(slected_prob_list)\n",
    "        if(prob<=threshold):\n",
    "            data_size = len(x)/n\n",
    "            cost = (alpha*data_size)+(1-alpha)*prob\n",
    "            if(cost<min_cost):\n",
    "                min_cost = cost\n",
    "                selected_subset = temp_list\n",
    "                \n",
    "    return selected_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = ['ST4000DM000', 'ST8000DM002', 'ST12000NM0007', 'ST8000NM0055', 'ST3000DM001', 'ST4000DX000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2fac0471b5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdisk_model_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisk_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#hdd = pd.read_csv(\"../dataset_1.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._concatenate_chunks\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for disk_model_name in selected_models:\n",
    "\n",
    "    hdd = pd.read_csv(\"../\"+str(number_of_days)+'/'+str(disk_model_name)+'.csv', header=None)\n",
    "    #hdd = pd.read_csv(\"../dataset_1.csv\")\n",
    "    hdd = hdd.drop(hdd.columns[6], axis=1)\n",
    "    hdd = hdd.drop(hdd.columns[9], axis=1)\n",
    "    hdd = hdd.drop(hdd.columns[14], axis=1)\n",
    "    hdd = hdd.drop(hdd.columns[13], axis=1)\n",
    "    hdd = hdd.dropna()\n",
    "#    print(hdd.head())\n",
    "    \n",
    "    hdd_extra = pd.read_csv(\"../2019_files/\"+str(number_of_days)+'/'+str(disk_model_name)+'.csv', header=None)\n",
    "#    print(hdd_extra.head())\n",
    "    hdd_extra = hdd_extra.drop(hdd_extra.columns[6], axis=1)\n",
    "    hdd_extra = hdd_extra.drop(hdd_extra.columns[9], axis=1)\n",
    "    hdd_extra = hdd_extra.drop(hdd_extra.columns[14], axis=1)\n",
    "    hdd_extra = hdd_extra.drop(hdd_extra.columns[13], axis=1)\n",
    "    hdd_extra = hdd_extra.dropna()\n",
    "    \n",
    "    hdd_merged = [hdd, hdd_extra]\n",
    "    result = pd.concat(hdd_merged)\n",
    "#    print(result.head())\n",
    "    #result = result.dropna()\n",
    "    \n",
    "    x = result.iloc[:, :-1].values\n",
    "    y = result.iloc[:, -1].values\n",
    "    \n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler()\n",
    "    \n",
    "    del hdd\n",
    "    del hdd_extra\n",
    "    del hdd_merged\n",
    "    del result\n",
    "    gc.collect()\n",
    "    \n",
    "    X_resampled, y_resampled = rus.fit_resample(x, y)\n",
    "    print(Counter(y_resampled))\n",
    "#    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.1, random_state=42)\n",
    "    clf=RandomForestClassifier()\n",
    "    clf.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
